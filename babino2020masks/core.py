# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['GAMMA', 'api_settings', 'nofilt', 'API', 'massachusetts_getter', 'michigan_getter', 'rhode_island_getter',
           'NEW_YORK_EVENTS', 'colorblind', 'plot_data_and_fit']

# Cell
import os
import io
from zipfile import ZipFile, BadZipFile
from datetime import datetime, timedelta

import pandas as pd
import requests
from fastcore.all import *
import seaborn as sns
from matplotlib import pyplot as plt
import numpy as np
from bs4 import BeautifulSoup

# Cell
sns.set_style("whitegrid")
sns.set_context("notebook", font_scale=1.5, rc={"lines.linewidth": 2.5})

# Cell
GAMMA = 1/7.5

# Cell
api_settings = {
                'NYS':         ("https://health.data.ny.gov/resource/xdss-u53e.csv/",
                                ['test_date', 'total_number_of_tests', 'new_positives'],
                                {}),
                'Connecticut': ("https://data.ct.gov/resource/qfkt-uahj.csv",
                                ['date', 'number_of_pcr_tests', 'number_of_pcr_positives']),
                'Virginia':    ('https://data.virginia.gov/resource/3u5k-c2gr.csv/',
                                ['lab_report_date', 'number_of_pcr_testing', 'number_of_positive_pcr_testing'],
                                {'date_ff': ne('Not Reported')}),
                }

# Cell
def nofilt(x): return True

# Cell
class API:
    def __init__(self, settings, date_ff=nofilt, custom_getter=None):
        store_attr(but='settings')
        self.url_base, self.usecols = settings
        self.pretty_cols = ['Date', 'Tests', 'Positives']#[x.split('_')[-1].capitalize() for x in self.usecols]

    def get_data(self, offset=0, limit=5000):
        url = self.url_base + f'?$limit={limit}&$offset={offset}'
        return pd.read_csv(url, usecols=self.usecols)[self.usecols]

    def iter_data(self, offset=0, limit=5000):
        df = pd.DataFrame(columns=self.usecols)
        while True:
            df = self.get_data(offset=offset, limit=limit)
            if len(df)==0: return
            offset += limit
            yield  df

    def get_all_data(self):
        df = pd.DataFrame(columns=self.usecols)
        for o in self.iter_data(): df = df.append(o)
        return df

    def standarize(self, df):
        df = df.rename(columns={k:v for k,v in zip(self.usecols, self.pretty_cols)})
        df = df[df.Date.map(self.date_ff)]
        if 'Date' in df.columns: df['Date'] = pd.to_datetime(df['Date'])
        return df

    def get_all_data_statewide(self, min_date='2020-03-15'):
        '''Gets statewide aggregated data.'''
        df = self.custom_getter(self.url_base, self.usecols) if self.custom_getter else self.get_all_data()
        df =  self.standarize(df)
        assert 'Date' in df.columns, 'data do not have Date column'
        df['date'] = df['Date']
        df = df.groupby('date').sum()
        df['Date'] = pd.to_datetime(df.index)
        df['Odds'] = df.Positives / (df.Tests - df.Positives)
        df = df[df.Date>=min_date]
        return df

# Cell
def massachusetts_getter(url_base, usecols):
    settings = api_settings['Massachusetts']
    # try today's file, if it fails try with yetarday's file.
    try:
        date_str = datetime.today().strftime('%B-%d-%Y').lower()
        url = url_base.format(date_str)
        r = requests.get(url, allow_redirects=True)
        zf = ZipFile(io.BytesIO(r.content))
    except BadZipFile:
        date_str = (datetime.today()-timedelta(1)).strftime('%B-%d-%Y').lower()
        url = url_base.format(date_str)
        r = requests.get(url, allow_redirects=True)
        zf = ZipFile(io.BytesIO(r.content))
    filename = L(zf.filelist).attrgot('filename').filter(Self.startswith('TestingByDate'))[0]
    csvf = zf.open(filename)
    if filename.split('.')[1]=='csv': df = pd.read_csv(csvf, usecols=susecols)
    elif filename.split('.')[1]=='xlsx': df = pd.read_excel(csvf, usecols=usecols)
    return df

# Cell
api_settings['Massachusetts'] = ('https://www.mass.gov/doc/covid-19-raw-data-{}/download',
                                 ['Date', 'Molecular New', 'Molecular Positive New'],
                                 {'custom_getter': massachusetts_getter})

# Cell
def michigan_getter(base_url, usecols):
    r = requests.get(base_url + '/coronavirus/0,9753,7-406-98163_98173---,00.html')
    soup = BeautifulSoup(r.content)
    a = soup.findAll('a')
    hrefs = L(a).itemgot('href')
    href = hrefs.filter(Self.startswith('/documents/coronavirus/Diagnostic_Tests_by_Result_and_County'))[0]
    return pd.read_excel(base_url + href, usecols=usecols)[usecols]

# Cell
api_settings['Michigan'] = ('https://www.michigan.gov',
                            ['MessageDate', 'Total', 'Positive'],
                            {'custom_getter': michigan_getter})

# Cell
def rhode_island_getter(base_url, usecols): return pd.read_csv(base_url, usecols=usecols)[usecols]

# Cell
api_settings['Rhode Island'] = ('https://docs.google.com/spreadsheets/d/1c2QrNMz8pIbYEKzMJL7Uh2dtThOJa2j1sSMwiDo5Gz4/export?format=csv&gid=1592746937',
                                ['Date', 'Daily total tests completed (may count people more than once)', 'Daily number of positive tests (may count people more than once)'],
                                {'custom_getter': rhode_island_getter})

# Cell
NEW_YORK_EVENTS = L('03-16-2020 20:00',
                    '03-18-2020 20:00',
                    '03-20-2020 20:00',
                    '03-22-2020 00:00',
                    '04-03-2020 00:00',
                    '04-12-2020 00:00',
                    '04-17-2020 00:00').map(pd.to_datetime)

# Cell
colorblind = sns.palettes.color_palette('colorblind')

# Cell
@delegates(plt.plot)
def plot_data_and_fit(df, x, y, y_hat, yl, yu, logy=True, palette=None, ax=None, **kwargs):
    palette = ifnone(palette, sns.palettes.color_palette('colorblind'))
    if not ax: fig, ax = plt.subplots(**kwargs)
    if y: df.plot.scatter(x=x, y=y, logy=logy, ax=ax, c=np.array(palette[0])[None,:], label=y)
    if y_hat: df.plot(x=x, y=y_hat, logy=logy, ax=ax, c=palette[1], label=y_hat)
    if yl: plt.fill_between(df.index, df[yl], df[yu], alpha=0.2, color=palette[1], label='95%CI');
    hl = ax.get_legend_handles_labels()
    hl2 = L((h, l) for h,l in zip(*hl) if not l.startswith('95'))
    ax.legend(hl2.itemgot(0), hl2.itemgot(1))
    min_y = df[yl].min() if yl else df[y].min()
    max_y = df[yu].max() if yl else df[y].max()
    ax.set_ylim([0.9*min_y, 1.1*max_y])
    return ax